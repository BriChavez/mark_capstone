{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mark_text = \"One hundred years ago the Russian mathematician A. A. Markov founded a new branch of probability theory by applying mathematics to poetry. Delving into the text of Alexander Pushkin’s novel in verse Eugene Onegin , Markov spent hours sifting through patterns of vowels and consonants. On January 23, 1913, he summarized his findings in an address to the Imperial Academy of Sciences in St. Petersburg. His analysis did not alter the understanding or appreciation of Pushkin’s poem, but the technique he developed—now known as a Markov chain—extended the theory of probability in a new direction. Markov’s methodology went beyond coin-flipping and dice-rolling situations (where each event is independent of all others) to chains of linked events (where what happens next depends on the current state of the system).\"\n",
    "\n",
    "# expanded_text = ' '.join(expanded_words)\n",
    "# print('Original text: ' + text)\n",
    "# print('Expanded_text: ' + expanded_text)\n",
    "\n",
    "# regex to keep only punctuation or words more than two letters long, may or may not contain an apostrophe in the middle\n",
    "resume_string = re.findall(r\"[a-z]+[']?[a-z]+|[.,]\", mark_text.lower())\n",
    "# adds things to out list of unwanted words\n",
    "more_drops = ['state', 'city', 'name', 'company',\n",
    "              'college', 'am', 'the', 'to', 'in']\n",
    "# toss those words to the curbs\n",
    "stop_dropped_resume = [w for w in resume_string if not w in more_drops]\n",
    "# Here, we will expand contractions\n",
    "expanded_words = []\n",
    "for word in stop_dropped_resume:\n",
    "  # using contractions.fix to expand the shortened words\n",
    "  expanded_words.append(contractions.fix(word))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "from numpy.random import choice\n",
    "import contractions\n",
    "# import contractions\n",
    "\n",
    "\"\"\"LET'S GET STARTED\"\"\"\n",
    "\n",
    "# open our file\n",
    "with open('data/bri/data_stack_resumes.txt', 'r') as resume_script:\n",
    "    # open txt file and read to string\n",
    "    resume_file = resume_script.read()\n",
    "    # lowercase everything in the string\n",
    "    resume_file = resume_file.lower()\n",
    "# r\"(?=.*\\w) ^ (\\w |')+$\"\n",
    "# resume_string = re.findall(r\"[a-z]+|[.,]\", resume_file)\n",
    "# resume_string = re.findall(r\"[.,]|(\\w+[']?\\w){2,}\", resume_file)\n",
    "# re.sub(r\"(\\n)\", \"  \", resume_file)\n",
    "resume_string = re.findall(r\"[.,]|[a-z]+[']?[a-z]+\", resume_file)\n",
    "# adds things to out list of unwanted words\n",
    "more_drops = ['state', 'city', 'name', 'company',\n",
    "              'college', 'an', 'the', 'to', 'in', 'am']\n",
    "# toss those words to the curbs\n",
    "stop_dropped_resume = [w for w in resume_string if not w in more_drops]\n",
    "\n",
    "expanded_words = []\n",
    "for word in stop_dropped_resume:\n",
    "  # using contractions.fix to expand the shortened words\n",
    "  expanded_words.append(contractions.fix(word))\n",
    "# resume_string2 = ' '.join(word for word in resume_string if len(word) > 2)\n",
    "print(expanded_words)\n",
    "# print(stop_dropped_resume[:1000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Resume/CONSTRUCTION\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "with open('data/bri/data_stack_resumes.txt', 'r') as resume_script:\n",
    "    # open txt file and read to string\n",
    "    resume_file = resume_script.read().lower()\n",
    "    \n",
    "\n",
    "# expanded_words = []\n",
    "# # resume_file.split()\n",
    "# for word in resume_file.split():\n",
    "#   # using contractions.fix to expand the shortened words\n",
    "#   expanded_words.append(contractions.fix(word))\n",
    "# print(expanded_words)\n",
    "\n",
    "# #convert it to dictionary with values and its occurences\n",
    "\n",
    "\n",
    "# word_cloud_dict = Counter(expanded_words)\n",
    "\n",
    "# wordcloud = WordCloud(\n",
    "#     width=1000, height=500).generate_from_frequencies(word_cloud_dict)\n",
    "\n",
    "# plt.figure(figsize=(15, 8))\n",
    "# plt.imshow(wordcloud)\n",
    "# plt.axis(\"off\")\n",
    "# #plt.show()\n",
    "# plt.savefig('data/bri/word_cloud_counter.png', bbox_inches='tight')\n",
    "# plt.close()\n",
    "parriable = 'construction'\n",
    "folder_path = f'data/Resume/{parriable.upper()}'\n",
    "print(folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_dict = {}\n",
    "# for loop that runs over every word in our string, but stating to stop at the last word\n",
    "for i, word in enumerate(expanded_words[:-1]):\n",
    "    # setting this word to be the word right after the one we were on\n",
    "    this_word = expanded_words[i-1]\n",
    "    # if this_word isn't in our dictionary already...\n",
    "    if this_word not in resume_dict:\n",
    "        # start our counter dict\n",
    "        next_count = {}\n",
    "        # add our new word to be a key in our resume dict and the count dict to be its value\n",
    "        resume_dict[this_word] = next_count\n",
    "    # if it is already in there....\n",
    "    else:\n",
    "        # create empty dictionary with this_word as the key and next_count as the value\n",
    "        next_count = resume_dict[this_word]\n",
    "    # if the next word(word) is in our nested dict already...\n",
    "    if word in next_count:\n",
    "        # add one to its count\n",
    "        next_count[word] += 1\n",
    "    # if its not already in there\n",
    "    else:\n",
    "        # lets add it and set its count to 1\n",
    "        next_count[word] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get inner keys\n",
    "inner_keys = list(resume_dict.values()[0]).keys()\n",
    "\n",
    "# x-axis is the outer keys\n",
    "x_axis_values = list(map(str, resume_dict.keys()))\n",
    "\n",
    "# loop through inner_keys\n",
    "for x in inner_keys:\n",
    "\n",
    "    # create a list of values for inner key\n",
    "    y_axis_values = [v[x] for v in resume_dict.values()]\n",
    "\n",
    "    # plot each inner key\n",
    "    plt.plot(x_axis_values, y_axis_values, label=x)\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected character found when decoding 'false'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4966/622183523.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# json.dumps(resume_dict, sort_keys=True, indent=3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished_resumes/mark_graph.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m             )\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected character found when decoding 'false'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"finished_resumes/marc_graph.json\", \"w\") as jason:\n",
    "    json.dump(resume_dict, jason, indent=3)\n",
    "# json.dumps(resume_dict, sort_keys=True, indent=3))\n",
    "df = pd.read_json(\"finished_resumes/mark_graph.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fields' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4966/2339214594.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finished_resumes/full_data_stacked.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fields' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "\n",
    "with open('finished_resumes/full_data_stacked.csv', \"wb\") as f:\n",
    "    w = csv.DictWriter(f, fields)\n",
    "    w.writeheader()\n",
    "    for k in dw:\n",
    "        w.writerow({field: dw[k].get(field) or k for field in fields})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.drawing.nx_pydot import write_dot\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "states = [(0, 0),\n",
    "          (1, 0),\n",
    "          (2, 0),]\n",
    "\n",
    "\n",
    "Q = [[5, 5, 0.4],\n",
    "     [1, 2, 3],\n",
    "     [4, 0.7, 0]\n",
    "     ]\n",
    "\n",
    "# G = nx.DiGraph()\n",
    "G = nx.MultiDiGraph()\n",
    "labels={}\n",
    "edge_labels={}\n",
    "\n",
    "for i, origin_state in enumerate(states):\n",
    "    for j, destination_state in enumerate(states):\n",
    "        rate = Q[i][j]\n",
    "        if rate > 0:\n",
    "            G.add_edge(origin_state, destination_state, weight=rate, label=\"{:.02f}\".format(rate))\n",
    "            edge_labels[(origin_state, destination_state)] = label=\"{:.02f}\".format(rate)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "node_size = 200\n",
    "pos = {state:list(state) for state in states}\n",
    "nx.draw_networkx_edges(G,pos,width=1.0,alpha=0.5)\n",
    "nx.draw_networkx_labels(G, pos, font_weight=2)\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "plt.axis('off');\n",
    "plt.show()\n",
    "\n",
    "write_dot(G, 'mc.dot')\n",
    "\n",
    "from subprocess import check_call\n",
    "nfile = 'w.png' \n",
    "check_call(['dot', '-Tpng', 'mc.dot', '-o', nfile])\n",
    "\n",
    "import matplotlib.image as mpimg\n",
    "img = mpimg.imread(nfile)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import string\n",
    "\n",
    "from typing import Optional\n",
    "from os import path\n",
    "\n",
    "from constants import *\n",
    "\n",
    "\n",
    "class Table:\n",
    "    \"\"\"\n",
    "    Table is an abstraction for table in draw.io\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, rows: Optional[dict] = None) -> None:\n",
    "        \"\"\"\n",
    "        Init method for table\n",
    "        :param name: Name of table\n",
    "        :param rows: Rows in table\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.rows = rows if rows else dict()\n",
    "\n",
    "\n",
    "class Page:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Page is an abstraction for whole page in draw.io.\n",
    "        There are objects on a page\n",
    "        \"\"\"\n",
    "        self.tables = []\n",
    "\n",
    "    def export(self, to_file: Optional[str] = DEFAULT_FILE_NAME) -> None:\n",
    "        \"\"\"\n",
    "        Main method that converts tables on a page into xml (drawio format)\n",
    "        :param to_file: Path of resulting .drawio file\n",
    "        \"\"\"\n",
    "        # check tables are correct\n",
    "        self.overall_check(to_file)\n",
    "\n",
    "        table_x_axis = BASE_START_TABLE_X_AXIS\n",
    "        main_str = \"\"  # all text is written here\n",
    "        for table in self.tables:\n",
    "            # configuring table id and height\n",
    "            table_id = self.gen_id()\n",
    "            table_height = BASE_START_ROW_Y_AXIS * (len(table.rows) + 1)\n",
    "            # adding table to main_str\n",
    "            main_str += BASE_TABLE.format(table.name,\n",
    "                                          table_id,\n",
    "                                          table_x_axis,\n",
    "                                          table_height)\n",
    "\n",
    "            row_y_axis = BASE_START_ROW_Y_AXIS\n",
    "            for r_key, r_value in table.rows.items():\n",
    "                # configuring id and row value for row\n",
    "                row_id = self.gen_id()\n",
    "                row_value = f\"{r_key}: {r_value}\"\n",
    "                # adding row to table\n",
    "                main_str += BASE_ROW.format(row_id,\n",
    "                                            row_value,\n",
    "                                            table_id,\n",
    "                                            row_y_axis)\n",
    "                row_y_axis += BASE_START_ROW_Y_AXIS\n",
    "            table_x_axis += BASE_TABLE_X_AXIS_DIFFERENCE\n",
    "\n",
    "        # adding all text to main XML code\n",
    "        export_string = BASE_PAGE.format(main_str)\n",
    "        # saving to file\n",
    "        with open(to_file, \"w\") as f:\n",
    "            f.write(export_string)\n",
    "        return\n",
    "\n",
    "    def add_table(self, table: Table) -> None:\n",
    "        \"\"\"\n",
    "        Method that adds table to page\n",
    "        :param table: Table that will be added\n",
    "        \"\"\"\n",
    "        self.tables.append(table)\n",
    "\n",
    "    def overall_check(self, f_name: str) -> None:\n",
    "        \"\"\"\n",
    "        Method that checks all tables and name of resulting file\n",
    "        before exporting.\n",
    "        :param f_name: name of a resulting file\n",
    "        \"\"\"\n",
    "        if not f_name.endswith(\".drawio\"):\n",
    "            raise Exception(\"Resulting file must end with .drawio\")\n",
    "        for table in self.tables:\n",
    "            # check for mandatory fields in table (Default none)\n",
    "            # check for MANDATORY_TYPES variable\n",
    "            self.check_mandatory(table.rows)\n",
    "            # check if row value types are correct\n",
    "            # check for ACCEPTABLE_VALUE_TYPES variable\n",
    "            # to turn it off set CHECK_VALUE_ENABLED to False\n",
    "            if CHECK_VALUE_ENABLED:\n",
    "                for elm in table.rows.values():\n",
    "                    self.check_value(elm)\n",
    "\n",
    "    def import_from_json(self, path_to_json: str) -> None:\n",
    "        \"\"\"\n",
    "        Method that:\n",
    "        - imports data from json file\n",
    "        - converts to Table\n",
    "        - appends it to self.tables variable\n",
    "        :param path_to_json: name of json file\n",
    "        \"\"\"\n",
    "        # check if json exists and in correct extension\n",
    "        self.check_json(path_to_json)\n",
    "        # load file\n",
    "        with open(path_to_json, \"r\") as f:\n",
    "            raw_json = json.load(f)\n",
    "        # check file if not empty\n",
    "        if len(raw_json) == 0:\n",
    "            raise Exception(\"file is empty\")\n",
    "        for key, value in raw_json.items():\n",
    "            # checking row\n",
    "            self.check_row(value)\n",
    "            # transforming data to Table and appending\n",
    "            self.tables.append(Table(key, value))\n",
    "\n",
    "    @staticmethod\n",
    "    def gen_id() -> str:\n",
    "        \"\"\"\n",
    "        Method that generates random id\n",
    "        for table and rows\n",
    "        \"\"\"\n",
    "        # symbols from which id is made\n",
    "        chars = string.ascii_uppercase + string.digits\n",
    "        return ''.join(random.choice(chars) for _ in range(ID_LENGTH))\n",
    "\n",
    "    @staticmethod\n",
    "    def check_value(value: str) -> None:\n",
    "        \"\"\"\n",
    "        Method that checks if a row value is in allowed format\n",
    "        :param value: value type of row\n",
    "        \"\"\"\n",
    "        if value not in ACCEPTABLE_VALUE_TYPES:\n",
    "            raise Exception(f\"Type {value} is not allowed to be a value\")\n",
    "\n",
    "    @staticmethod\n",
    "    def check_mandatory(table: dict) -> None:\n",
    "        \"\"\"\n",
    "        Method that checks if there are required keys in table\n",
    "        :param table: all rows\n",
    "        \"\"\"\n",
    "        for elm in MANDATORY_TYPES:\n",
    "            if elm not in table:\n",
    "                raise Exception(f\"{elm} not found in table\")\n",
    "\n",
    "    @staticmethod\n",
    "    def check_json(name: str) -> None:\n",
    "        \"\"\"\n",
    "        Method that checks if json file is correct\n",
    "        :param name: name of json file\n",
    "        \"\"\"\n",
    "        # if it exists\n",
    "        if not path.exists(name):\n",
    "            raise Exception(\"File not found\")\n",
    "        # if it is in json format\n",
    "        if not name.endswith(\".json\"):\n",
    "            raise Exception(\"File does not end with .json\")\n",
    "\n",
    "    @staticmethod\n",
    "    def check_row(row: dict) -> None:\n",
    "        \"\"\"\n",
    "        Method that checks if row is in needed type\n",
    "        Allowed types:\n",
    "        - string\n",
    "        - number\n",
    "        :param row: a row {\"key\": \"value\"}\n",
    "        \"\"\"\n",
    "        for value in row.values():\n",
    "            if type(value) not in [str, int, float, complex]:\n",
    "                raise Exception(\"child value is not acceptable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \".\": {\n",
      "      \"one\": 1,\n",
      "      \".\": 1,\n",
      "      \"markov\": 2,\n",
      "      \"delving\": 1,\n",
      "      \"on\": 1,\n",
      "      \"petersburg\": 1,\n",
      "      \"his\": 1\n",
      "   },\n",
      "   \"one\": {\n",
      "      \"hundred\": 1\n",
      "   },\n",
      "   \"hundred\": {\n",
      "      \"years\": 1\n",
      "   },\n",
      "   \"years\": {\n",
      "      \"ago\": 1\n",
      "   },\n",
      "   \"ago\": {\n",
      "      \"russian\": 1\n",
      "   },\n",
      "   \"russian\": {\n",
      "      \"mathematician\": 1\n",
      "   },\n",
      "   \"mathematician\": {\n",
      "      \".\": 1\n",
      "   },\n",
      "   \"markov\": {\n",
      "      \"founded\": 1,\n",
      "      \"spent\": 1,\n",
      "      \"chain\": 1,\n",
      "      \"methodology\": 1\n",
      "   },\n",
      "   \"founded\": {\n",
      "      \"new\": 1\n",
      "   },\n",
      "   \"new\": {\n",
      "      \"branch\": 1,\n",
      "      \"direction\": 1\n",
      "   },\n",
      "   \"branch\": {\n",
      "      \"of\": 1\n",
      "   },\n",
      "   \"of\": {\n",
      "      \"probability\": 2,\n",
      "      \"alexander\": 1,\n",
      "      \"vowels\": 1,\n",
      "      \"sciences\": 1,\n",
      "      \"pushkin\": 1,\n",
      "      \"all\": 1,\n",
      "      \"linked\": 1,\n",
      "      \"system\": 1\n",
      "   },\n",
      "   \"probability\": {\n",
      "      \"theory\": 1,\n",
      "      \"new\": 1\n",
      "   },\n",
      "   \"theory\": {\n",
      "      \"by\": 1,\n",
      "      \"of\": 1\n",
      "   },\n",
      "   \"by\": {\n",
      "      \"applying\": 1\n",
      "   },\n",
      "   \"applying\": {\n",
      "      \"mathematics\": 1\n",
      "   },\n",
      "   \"mathematics\": {\n",
      "      \"poetry\": 1\n",
      "   },\n",
      "   \"poetry\": {\n",
      "      \".\": 1\n",
      "   },\n",
      "   \"delving\": {\n",
      "      \"into\": 1\n",
      "   },\n",
      "   \"into\": {\n",
      "      \"text\": 1\n",
      "   },\n",
      "   \"text\": {\n",
      "      \"of\": 1\n",
      "   },\n",
      "   \"alexander\": {\n",
      "      \"pushkin\": 1\n",
      "   },\n",
      "   \"pushkin\": {\n",
      "      \"novel\": 1,\n",
      "      \"poem\": 1\n",
      "   },\n",
      "   \"novel\": {\n",
      "      \"verse\": 1\n",
      "   },\n",
      "   \"verse\": {\n",
      "      \"eugene\": 1\n",
      "   },\n",
      "   \"eugene\": {\n",
      "      \"onegin\": 1\n",
      "   },\n",
      "   \"onegin\": {\n",
      "      \",\": 1\n",
      "   },\n",
      "   \",\": {\n",
      "      \"markov\": 1,\n",
      "      \",\": 1,\n",
      "      \"he\": 1,\n",
      "      \"but\": 1\n",
      "   },\n",
      "   \"spent\": {\n",
      "      \"hours\": 1\n",
      "   },\n",
      "   \"hours\": {\n",
      "      \"sifting\": 1\n",
      "   },\n",
      "   \"sifting\": {\n",
      "      \"through\": 1\n",
      "   },\n",
      "   \"through\": {\n",
      "      \"patterns\": 1\n",
      "   },\n",
      "   \"patterns\": {\n",
      "      \"of\": 1\n",
      "   },\n",
      "   \"vowels\": {\n",
      "      \"and\": 1\n",
      "   },\n",
      "   \"and\": {\n",
      "      \"consonants\": 1,\n",
      "      \"dice\": 1\n",
      "   },\n",
      "   \"consonants\": {\n",
      "      \".\": 1\n",
      "   },\n",
      "   \"on\": {\n",
      "      \"january\": 1,\n",
      "      \"current\": 1\n",
      "   },\n",
      "   \"january\": {\n",
      "      \",\": 1\n",
      "   },\n",
      "   \"he\": {\n",
      "      \"summarized\": 1,\n",
      "      \"developed\": 1\n",
      "   },\n",
      "   \"summarized\": {\n",
      "      \"his\": 1\n",
      "   },\n",
      "   \"his\": {\n",
      "      \"findings\": 1,\n",
      "      \"analysis\": 1\n",
      "   },\n",
      "   \"findings\": {\n",
      "      \"an\": 1\n",
      "   },\n",
      "   \"an\": {\n",
      "      \"address\": 1\n",
      "   },\n",
      "   \"address\": {\n",
      "      \"imperial\": 1\n",
      "   },\n",
      "   \"imperial\": {\n",
      "      \"academy\": 1\n",
      "   },\n",
      "   \"academy\": {\n",
      "      \"of\": 1\n",
      "   },\n",
      "   \"sciences\": {\n",
      "      \"st\": 1\n",
      "   },\n",
      "   \"st\": {\n",
      "      \".\": 1\n",
      "   },\n",
      "   \"petersburg\": {\n",
      "      \".\": 1\n",
      "   },\n",
      "   \"analysis\": {\n",
      "      \"did\": 1\n",
      "   },\n",
      "   \"did\": {\n",
      "      \"not\": 1\n",
      "   },\n",
      "   \"not\": {\n",
      "      \"alter\": 1\n",
      "   },\n",
      "   \"alter\": {\n",
      "      \"understanding\": 1\n",
      "   },\n",
      "   \"understanding\": {\n",
      "      \"or\": 1\n",
      "   },\n",
      "   \"or\": {\n",
      "      \"appreciation\": 1\n",
      "   },\n",
      "   \"appreciation\": {\n",
      "      \"of\": 1\n",
      "   },\n",
      "   \"poem\": {\n",
      "      \",\": 1\n",
      "   },\n",
      "   \"but\": {\n",
      "      \"technique\": 1\n",
      "   },\n",
      "   \"technique\": {\n",
      "      \"he\": 1\n",
      "   },\n",
      "   \"developed\": {\n",
      "      \"now\": 1\n",
      "   },\n",
      "   \"now\": {\n",
      "      \"known\": 1\n",
      "   },\n",
      "   \"known\": {\n",
      "      \"as\": 1\n",
      "   },\n",
      "   \"as\": {\n",
      "      \"markov\": 1\n",
      "   },\n",
      "   \"chain\": {\n",
      "      \"extended\": 1\n",
      "   },\n",
      "   \"extended\": {\n",
      "      \"theory\": 1\n",
      "   },\n",
      "   \"direction\": {\n",
      "      \".\": 1\n",
      "   },\n",
      "   \"methodology\": {\n",
      "      \"went\": 1\n",
      "   },\n",
      "   \"went\": {\n",
      "      \"beyond\": 1\n",
      "   },\n",
      "   \"beyond\": {\n",
      "      \"coin\": 1\n",
      "   },\n",
      "   \"coin\": {\n",
      "      \"flipping\": 1\n",
      "   },\n",
      "   \"flipping\": {\n",
      "      \"and\": 1\n",
      "   },\n",
      "   \"dice\": {\n",
      "      \"rolling\": 1\n",
      "   },\n",
      "   \"rolling\": {\n",
      "      \"situations\": 1\n",
      "   },\n",
      "   \"situations\": {\n",
      "      \"where\": 1\n",
      "   },\n",
      "   \"where\": {\n",
      "      \"each\": 1,\n",
      "      \"what\": 1\n",
      "   },\n",
      "   \"each\": {\n",
      "      \"event\": 1\n",
      "   },\n",
      "   \"event\": {\n",
      "      \"is\": 1\n",
      "   },\n",
      "   \"is\": {\n",
      "      \"independent\": 1\n",
      "   },\n",
      "   \"independent\": {\n",
      "      \"of\": 1\n",
      "   },\n",
      "   \"all\": {\n",
      "      \"others\": 1\n",
      "   },\n",
      "   \"others\": {\n",
      "      \"chains\": 1\n",
      "   },\n",
      "   \"chains\": {\n",
      "      \"of\": 1\n",
      "   },\n",
      "   \"linked\": {\n",
      "      \"events\": 1\n",
      "   },\n",
      "   \"events\": {\n",
      "      \"where\": 1\n",
      "   },\n",
      "   \"what\": {\n",
      "      \"happens\": 1\n",
      "   },\n",
      "   \"happens\": {\n",
      "      \"next\": 1\n",
      "   },\n",
      "   \"next\": {\n",
      "      \"depends\": 1\n",
      "   },\n",
      "   \"depends\": {\n",
      "      \"on\": 1\n",
      "   },\n",
      "   \"current\": {\n",
      "      \"of\": 1\n",
      "   }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"CREATE OUR NESTED DICT TO SAVE HOW OFTEN ONE WORD FOLLOWS ANOTHER\"\"\"\n",
    "import json\n",
    "\n",
    "\n",
    "print(json.dumps(resume_dict, indent=3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'dict_values' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4966/427401062.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# get inner keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minner_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# x-axis is the outer keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'dict_values' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unexpected character found when decoding 'false'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4966/1567119438.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# json.dumps(resume_dict, sort_keys=True, indent=3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"finished_resumes/mark_graph.json\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# df = df.T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# df.to_csv(\"finished_resumes/mark_graph.csv\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 770\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    771\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_no_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse_no_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1140\u001b[0;31m                 \u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1141\u001b[0m             )\n\u001b[1;32m   1142\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unexpected character found when decoding 'false'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"finished_resumes/marc_graph.json\", \"w\") as jason:\n",
    "    json.dump(resume_dict, jason, indent=3)\n",
    "# json.dumps(resume_dict, sort_keys=True, indent=3))\n",
    "df = pd.read_json(\"finished_resumes/mark_graph.json\")\n",
    "# df = df.T\n",
    "# df.to_csv(\"finished_resumes/mark_graph.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['markov']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"START THE STORY\"\"\"\n",
    "\n",
    "# starting out story off blank\n",
    "story = []\n",
    "# Pick the first word at random from our initial string\n",
    "first_word = random.choice(stop_dropped_resume)\n",
    "# while loop to make sure we dont start on punctuation\n",
    "while first_word in string.punctuation:\n",
    "    # if it was punctuation, choose again\n",
    "    first_word = random.choice(stop_dropped_resume)\n",
    "# if story is blank...\n",
    "if story == []:\n",
    "    # set story up with our first word\n",
    "    story.append(first_word)\n",
    "print(story)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DEFAULT_FILE_NAME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4966/4197872116.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mPage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \"\"\"\n",
      "\u001b[0;32m/tmp/ipykernel_4966/4197872116.py\u001b[0m in \u001b[0;36mPage\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mexport\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDEFAULT_FILE_NAME\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \"\"\"\n\u001b[1;32m     36\u001b[0m         \u001b[0mMain\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mconverts\u001b[0m \u001b[0mtables\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpage\u001b[0m \u001b[0minto\u001b[0m \u001b[0mxml\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdrawio\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEFAULT_FILE_NAME' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import string\n",
    "\n",
    "from typing import Optional\n",
    "from os import path\n",
    "\n",
    "from constants import *\n",
    "path_to_json = \"finished_resumes/marc_graph.json\"\n",
    "\n",
    "class Table:\n",
    "    \"\"\"\n",
    "    Table is an abstraction for table in draw.io\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name: str, rows: Optional[dict] = None) -> None:\n",
    "        \"\"\"\n",
    "        Init method for table\n",
    "        :param name: Name of table\n",
    "        :param rows: Rows in table\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        self.rows = rows if rows else dict()\n",
    "\n",
    "\n",
    "class Page:\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Page is an abstraction for whole page in draw.io.\n",
    "        There are objects on a page\n",
    "        \"\"\"\n",
    "        self.tables = []\n",
    "\n",
    "    def export(self, to_file: Optional[str] = DEFAULT_FILE_NAME) -> None:\n",
    "        \"\"\"\n",
    "        Main method that converts tables on a page into xml (drawio format)\n",
    "        :param to_file: Path of resulting .drawio file\n",
    "        \"\"\"\n",
    "        # check tables are correct\n",
    "        self.overall_check(to_file)\n",
    "\n",
    "        table_x_axis = BASE_START_TABLE_X_AXIS\n",
    "        main_str = \"\"  # all text is written here\n",
    "        for table in self.tables:\n",
    "            # configuring table id and height\n",
    "            table_id = self.gen_id()\n",
    "            table_height = BASE_START_ROW_Y_AXIS * (len(table.rows) + 1)\n",
    "            # adding table to main_str\n",
    "            main_str += BASE_TABLE.format(table.name,\n",
    "                                          table_id,\n",
    "                                          table_x_axis,\n",
    "                                          table_height)\n",
    "\n",
    "            row_y_axis = BASE_START_ROW_Y_AXIS\n",
    "            for r_key, r_value in table.rows.items():\n",
    "                # configuring id and row value for row\n",
    "                row_id = self.gen_id()\n",
    "                row_value = f\"{r_key}: {r_value}\"\n",
    "                # adding row to table\n",
    "                main_str += BASE_ROW.format(row_id,\n",
    "                                            row_value,\n",
    "                                            table_id,\n",
    "                                            row_y_axis)\n",
    "                row_y_axis += BASE_START_ROW_Y_AXIS\n",
    "            table_x_axis += BASE_TABLE_X_AXIS_DIFFERENCE\n",
    "\n",
    "        # adding all text to main XML code\n",
    "        export_string = BASE_PAGE.format(main_str)\n",
    "        # saving to file\n",
    "        with open(to_file, \"w\") as f:\n",
    "            f.write(export_string)\n",
    "        return\n",
    "\n",
    "    def add_table(self, table: Table) -> None:\n",
    "        \"\"\"\n",
    "        Method that adds table to page\n",
    "        :param table: Table that will be added\n",
    "        \"\"\"\n",
    "        self.tables.append(table)\n",
    "\n",
    "    def overall_check(self, f_name: str) -> None:\n",
    "        \"\"\"\n",
    "        Method that checks all tables and name of resulting file\n",
    "        before exporting.\n",
    "        :param f_name: name of a resulting file\n",
    "        \"\"\"\n",
    "        if not f_name.endswith(\".drawio\"):\n",
    "            raise Exception(\"Resulting file must end with .drawio\")\n",
    "        for table in self.tables:\n",
    "            # check for mandatory fields in table (Default none)\n",
    "            # check for MANDATORY_TYPES variable\n",
    "            self.check_mandatory(table.rows)\n",
    "            # check if row value types are correct\n",
    "            # check for ACCEPTABLE_VALUE_TYPES variable\n",
    "            # to turn it off set CHECK_VALUE_ENABLED to False\n",
    "            if CHECK_VALUE_ENABLED:\n",
    "                for elm in table.rows.values():\n",
    "                    self.check_value(elm)\n",
    "\n",
    "    def import_from_json(self, path_to_json: str) -> None:\n",
    "        \"\"\"\n",
    "        Method that:\n",
    "        - imports data from json file\n",
    "        - converts to Table\n",
    "        - appends it to self.tables variable\n",
    "        :param path_to_json: name of json file\n",
    "        \"\"\"\n",
    "        # check if json exists and in correct extension\n",
    "        self.check_json(path_to_json)\n",
    "        # load file\n",
    "        with open(path_to_json, \"r\") as f:\n",
    "            raw_json = json.load(f)\n",
    "        # check file if not empty\n",
    "        if len(raw_json) == 0:\n",
    "            raise Exception(\"file is empty\")\n",
    "        for key, value in raw_json.items():\n",
    "            # checking row\n",
    "            self.check_row(value)\n",
    "            # transforming data to Table and appending\n",
    "            self.tables.append(Table(key, value))\n",
    "\n",
    "    @staticmethod\n",
    "    def gen_id() -> str:\n",
    "        \"\"\"\n",
    "        Method that generates random id\n",
    "        for table and rows\n",
    "        \"\"\"\n",
    "        # symbols from which id is made\n",
    "        chars = string.ascii_uppercase + string.digits\n",
    "        return ''.join(random.choice(chars) for _ in range(ID_LENGTH))\n",
    "\n",
    "    @staticmethod\n",
    "    def check_value(value: str) -> None:\n",
    "        \"\"\"\n",
    "        Method that checks if a row value is in allowed format\n",
    "        :param value: value type of row\n",
    "        \"\"\"\n",
    "        if value not in ACCEPTABLE_VALUE_TYPES:\n",
    "            raise Exception(f\"Type {value} is not allowed to be a value\")\n",
    "\n",
    "    @staticmethod\n",
    "    def check_mandatory(table: dict) -> None:\n",
    "        \"\"\"\n",
    "        Method that checks if there are required keys in table\n",
    "        :param table: all rows\n",
    "        \"\"\"\n",
    "        for elm in MANDATORY_TYPES:\n",
    "            if elm not in table:\n",
    "                raise Exception(f\"{elm} not found in table\")\n",
    "\n",
    "    @staticmethod\n",
    "    def check_json(name: str) -> None:\n",
    "        \"\"\"\n",
    "        Method that checks if json file is correct\n",
    "        :param name: name of json file\n",
    "        \"\"\"\n",
    "        # if it exists\n",
    "        if not path.exists(name):\n",
    "            raise Exception(\"File not found\")\n",
    "        # if it is in json format\n",
    "        if not name.endswith(\".json\"):\n",
    "            raise Exception(\"File does not end with .json\")\n",
    "\n",
    "    @staticmethod\n",
    "    def check_row(row: dict) -> None:\n",
    "        \"\"\"\n",
    "        Method that checks if row is in needed type\n",
    "        Allowed types:\n",
    "        - string\n",
    "        - number\n",
    "        :param row: a row {\"key\": \"value\"}\n",
    "        \"\"\"\n",
    "        for value in row.values():\n",
    "            if type(value) not in [str, int, float, complex]:\n",
    "                raise Exception(\"child value is not acceptable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "{'one': 1, '.': 1, 'markov': 2, 'delving': 1, 'on': 1, 'petersburg': 1, 'his': 1}\n",
      "one\n",
      "{'hundred': 1}\n",
      "hundred\n",
      "{'years': 1}\n",
      "years\n",
      "{'ago': 1}\n",
      "ago\n",
      "{'russian': 1}\n",
      "russian\n",
      "{'mathematician': 1}\n",
      "mathematician\n",
      "{'.': 1}\n",
      "markov\n",
      "{'founded': 1, 'spent': 1, 'chain': 1, 'methodology': 1}\n",
      "founded\n",
      "{'new': 1}\n",
      "new\n",
      "{'branch': 1, 'direction': 1}\n",
      "branch\n",
      "{'of': 1}\n",
      "of\n",
      "{'probability': 2, 'alexander': 1, 'vowels': 1, 'sciences': 1, 'pushkin': 1, 'all': 1, 'linked': 1, 'system': 1}\n",
      "probability\n",
      "{'theory': 1, 'new': 1}\n",
      "theory\n",
      "{'by': 1, 'of': 1}\n",
      "by\n",
      "{'applying': 1}\n",
      "applying\n",
      "{'mathematics': 1}\n",
      "mathematics\n",
      "{'poetry': 1}\n",
      "poetry\n",
      "{'.': 1}\n",
      "delving\n",
      "{'into': 1}\n",
      "into\n",
      "{'text': 1}\n",
      "text\n",
      "{'of': 1}\n",
      "alexander\n",
      "{'pushkin': 1}\n",
      "pushkin\n",
      "{'novel': 1, 'poem': 1}\n",
      "novel\n",
      "{'verse': 1}\n",
      "verse\n",
      "{'eugene': 1}\n",
      "eugene\n",
      "{'onegin': 1}\n",
      "onegin\n",
      "{',': 1}\n",
      ",\n",
      "{'markov': 1, ',': 1, 'he': 1, 'but': 1}\n",
      "spent\n",
      "{'hours': 1}\n",
      "hours\n",
      "{'sifting': 1}\n",
      "sifting\n",
      "{'through': 1}\n",
      "through\n",
      "{'patterns': 1}\n",
      "patterns\n",
      "{'of': 1}\n",
      "vowels\n",
      "{'and': 1}\n",
      "and\n",
      "{'consonants': 1, 'dice': 1}\n",
      "consonants\n",
      "{'.': 1}\n",
      "on\n",
      "{'january': 1, 'current': 1}\n",
      "january\n",
      "{',': 1}\n",
      "he\n",
      "{'summarized': 1, 'developed': 1}\n",
      "summarized\n",
      "{'his': 1}\n",
      "his\n",
      "{'findings': 1, 'analysis': 1}\n",
      "findings\n",
      "{'an': 1}\n",
      "an\n",
      "{'address': 1}\n",
      "address\n",
      "{'imperial': 1}\n",
      "imperial\n",
      "{'academy': 1}\n",
      "academy\n",
      "{'of': 1}\n",
      "sciences\n",
      "{'st': 1}\n",
      "st\n",
      "{'.': 1}\n",
      "petersburg\n",
      "{'.': 1}\n",
      "analysis\n",
      "{'did': 1}\n",
      "did\n",
      "{'not': 1}\n",
      "not\n",
      "{'alter': 1}\n",
      "alter\n",
      "{'understanding': 1}\n",
      "understanding\n",
      "{'or': 1}\n",
      "or\n",
      "{'appreciation': 1}\n",
      "appreciation\n",
      "{'of': 1}\n",
      "poem\n",
      "{',': 1}\n",
      "but\n",
      "{'technique': 1}\n",
      "technique\n",
      "{'he': 1}\n",
      "developed\n",
      "{'now': 1}\n",
      "now\n",
      "{'known': 1}\n",
      "known\n",
      "{'as': 1}\n",
      "as\n",
      "{'markov': 1}\n",
      "chain\n",
      "{'extended': 1}\n",
      "extended\n",
      "{'theory': 1}\n",
      "direction\n",
      "{'.': 1}\n",
      "methodology\n",
      "{'went': 1}\n",
      "went\n",
      "{'beyond': 1}\n",
      "beyond\n",
      "{'coin': 1}\n",
      "coin\n",
      "{'flipping': 1}\n",
      "flipping\n",
      "{'and': 1}\n",
      "dice\n",
      "{'rolling': 1}\n",
      "rolling\n",
      "{'situations': 1}\n",
      "situations\n",
      "{'where': 1}\n",
      "where\n",
      "{'each': 1, 'what': 1}\n",
      "each\n",
      "{'event': 1}\n",
      "event\n",
      "{'is': 1}\n",
      "is\n",
      "{'independent': 1}\n",
      "independent\n",
      "{'of': 1}\n",
      "all\n",
      "{'others': 1}\n",
      "others\n",
      "{'chains': 1}\n",
      "chains\n",
      "{'of': 1}\n",
      "linked\n",
      "{'events': 1}\n",
      "events\n",
      "{'where': 1}\n",
      "what\n",
      "{'happens': 1}\n",
      "happens\n",
      "{'next': 1}\n",
      "next\n",
      "{'depends': 1}\n",
      "depends\n",
      "{'on': 1}\n",
      "current\n",
      "{'of': 1}\n"
     ]
    }
   ],
   "source": [
    "for outer_word, inner_dict in resume_dict.items():\n",
    "    # get the next words and instances\n",
    "    outer_word = outer_word\n",
    "    print(outer_word)\n",
    "    print(inner_dict)\n",
    "    total_occurances = inner_dict.values()\n",
    "    for key, value in inner_dict.items():\n",
    "        dict_key = key\n",
    "        dict_value = value\n",
    "    # seperate the instances\n",
    "    \n",
    "        # print(word_self_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4966/3248924216.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresume_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'level_0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer_word'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'key'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id:N'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4966/3248924216.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresume_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'level_0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'id'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mChart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer_word'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'key'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'id:N'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    612\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     return arrays_to_mgr(\n\u001b[0;32m--> 465\u001b[0;31m         \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     )\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import altair as alt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.concat({k: pd.DataFrame(d) for k, d in resume_dict.items()})\n",
    "df = df.reset_index(0).rename({'level_0': 'id'}, axis=1)\n",
    "alt.Chart(df).mark_line().encode(x='outer_word',y='value',index = 'key', color='id:N')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (7,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4966/3162266922.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# plot each inner key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_axis_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_axis_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2769\u001b[0m     return gca().plot(\n\u001b[1;32m   2770\u001b[0m         \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2771\u001b[0;31m         **({\"data\": data} if data is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1630\u001b[0m         \"\"\"\n\u001b[1;32m   1631\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deb/tests/capstone/venv/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    499\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    500\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (7,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# get inner keys\n",
    "inner_keys = list(dict_key)\n",
    "\n",
    "# x-axis is the outer keys\n",
    "x_axis_values = list(map(str, outer_word))\n",
    "\n",
    "# loop through inner_keys\n",
    "\n",
    "\n",
    "    # create a list of values for inner key\n",
    "y_axis_values = value\n",
    "\n",
    "    # plot each inner key\n",
    "plt.plot(x_axis_values, y_axis_values, label=x)\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['markov', 'chain', 'extended', 'theory', 'by', 'applying', 'mathematics', 'poetry', '.', 'markov', 'spent', 'hours', 'sifting', 'through', 'patterns', 'of', 'pushkin', 'poem', ',', ',', 'markov', 'methodology', 'went', 'beyond', 'coin', 'flipping', 'and', 'consonants', '.', 'markov', 'methodology', 'went', 'beyond', 'coin', 'flipping', 'and', 'dice', 'rolling', 'situations', 'where', 'what', 'happens', 'next', 'depends', 'on', 'current', 'of', 'pushkin', 'novel', 'verse', 'eugene', 'onegin', ',', 'but', 'technique', 'he', 'summarized', 'his', 'analysis', 'did', 'not', 'alter', 'understanding', 'or', 'appreciation', 'of', 'system']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"CREATE THE WEIGHTED PROB ALGORITHM TO DETERMINE THE NEXT WORD\"\"\"\n",
    "\n",
    "# function to get the next word using weighted probability\n",
    "\n",
    "\n",
    "def whos_next():\n",
    "    # set our current word to be the last word of the story string\n",
    "    current_word = story[-1]\n",
    "    # pick out our nested dict for specific word\n",
    "    for outer_word, inner_dict in resume_dict.items():\n",
    "        # get the next words and instances\n",
    "        word_self_total = inner_dict.items()\n",
    "        # seperate the instances\n",
    "        total_occurances = inner_dict.values()\n",
    "        # pull the dictionary for the current word\n",
    "        if outer_word == current_word:\n",
    "            # add the total times a word followed current word\n",
    "            total = sum(total_occurances)\n",
    "            # set empty variable for the percent chance of each word occuring\n",
    "            probs = []\n",
    "            # set a list of all words that came after current word\n",
    "            hopefuls = []\n",
    "            # set an empty list to grab the count of each word\n",
    "            likely = []\n",
    "            # pull every number of times each word came after current\n",
    "            for number in total_occurances:\n",
    "                # factor the percent chance of a word being next\n",
    "                percent = number / total\n",
    "                # add each percent to our probs list\n",
    "                probs.append(percent)\n",
    "            # pull words and their values from our inner dict\n",
    "            for word, num in word_self_total:\n",
    "                # add each word to our hopefuls list\n",
    "                hopefuls.append(word)\n",
    "                # add each number to our likely list\n",
    "                likely.append(num)\n",
    "            # making our rng_says a global variable\n",
    "            global rng_says\n",
    "            # weighted rng based off the percent probability of word occuring\n",
    "            rng_says = choice(hopefuls, p=probs)\n",
    "            # change rng output from numpy to string\n",
    "            next_word = str(rng_says)\n",
    "            # add our next word string to the story\n",
    "            story.append(next_word)\n",
    "whos_next()\n",
    "\n",
    "# mark_text = \"One hundred years ago the Russian mathematician A. A. Markov founded a new branch of probability theory by applying mathematics to poetry. Delving into the text of Alexander Pushkin’s novel in verse Eugene Onegin , Markov spent hours sifting through patterns of vowels and consonants. On January 23, 1913, he summarized his findings in an address to the Imperial Academy of Sciences in St. Petersburg. His analysis did not alter the understanding or appreciation of Pushkin’s poem, but the technique he developed—now known as a Markov chain—extended the theory of probability in a new direction. Markov’s methodology went beyond coin-flipping and dice-rolling situations (where each event is independent of all others) to chains of linked events (where what happens next depends on the current state of the system).\"\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36837/4065312408.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mwhos_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwhole_story\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhole_story\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_36837/117274144.py\u001b[0m in \u001b[0;36mwhos_next\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mword_self_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# seperate the instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtotal_occurances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# pull the dictionary for the current word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mouter_word\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurrent_word\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while len(story) < 400:\n",
    "    whos_next()\n",
    "whole_story = ' '.join(story)\n",
    "print(whole_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4966/470836706.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# call our function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mwhos_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# set our full story to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_4966/4218121770.py\u001b[0m in \u001b[0;36mwhos_next\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mword_self_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# seperate the instances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtotal_occurances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minner_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# pull the dictionary for the current word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mouter_word\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcurrent_word\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"ADD WORDS TO OUR STORY, DROP WHITE SPACE, CAPITALIZE, AND NEWLINE\"\"\"\n",
    "# story = ['markov', 'chain', 'extended', 'theory', 'by', 'applying', 'mathematics', 'poetry', '.', 'markov', 'methodology', 'went', 'beyond', 'coin', 'flipping', 'and', 'consonants', '.', 'petersburg', '.', 'markov', 'spent', 'hours', 'sifting', 'through', 'patterns',\n",
    "#          'of', 'probability', 'theory', 'by', 'applying', 'mathematics', 'poetry', '.', 'his', 'findings', 'an', 'address', 'imperial', 'academy', 'of', 'linked', 'events', 'where', 'each', 'event', 'is', 'independent', 'of', 'vowels', 'and', 'consonants', '.', ]\n",
    "\n",
    "while len(story) < 400:\n",
    "    # call our function\n",
    "    whos_next()\n",
    "# set our full story to be\n",
    "\n",
    "whole_story = ' '.join(story)\n",
    "print(whole_story)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace white space preceding punctuation\n",
    "whole_story = re.sub(r'\\s([?.,!](?:\\s|$))', r'\\1', whole_story)\n",
    "# resplit the story, this time on sentences\n",
    "sentences = re.split('[?.]', whole_story)\n",
    "\n",
    "# set a new clean variable\n",
    "cap_sent = []\n",
    "# for every sentense in our story...\n",
    "for sentence in sentences:\n",
    "    # strip the left white space and capitalize the first word and add it to a new list\n",
    "    cap_sent.append((sentence.lstrip().capitalize() + '.'))\n",
    "# turn our story back into a string by joining them back in together\n",
    "cap_sent = ' '.join(cap_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMarkov chain extended theory by applying mathematics poetry. Markov methodology went beyond coin flipping and consonants. Petersburg. Markov spent hours sifting through patterns of probability theory by applying mathematics poetry.\n",
      "\tHis findings an address imperial academy of linked events where each event is independent of vowels and consonants. .\n"
     ]
    }
   ],
   "source": [
    "# back to splitting our text on periods\n",
    "splittext = cap_sent.split(\".\")\n",
    "# for every 5 to 10 sentences...\n",
    "for x in range(4, len(splittext), random.randint(5, 8)):\n",
    "    # add a new line and start the next sentence tabbed in\n",
    "    splittext[x] = \"\\n\"+\"\\t\"+splittext[x].lstrip()\n",
    "# throw it all back together into a string\n",
    "text = \".\".join(splittext)\n",
    "# add a tab to the first line so it matches its friends\n",
    "text = f'\\t'+text\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"SPELL CHECK AND SAVE\"\"\"\n",
    "import language_tool_python\n",
    "# set our spell check function to english and assign it to a variable\n",
    "\n",
    "tool = language_tool_python.LanguageTool('en-US')\n",
    "# set our checker to autocorrect\n",
    "checked_text = tool.correct(cap_sent)\n",
    "# open a new file in the generated resume folder\n",
    "text_file = open(f'finished_resumes/marks_mark.txt', 'w')\n",
    "# write our resume to it\n",
    "text_file.write(checked_text)\n",
    "# shut it down. our work here is done\n",
    "text_file.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36837/4189203426.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'finished_resumes/full_data_stacked.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchecked_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m        \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ef022e24af0d9896d2df829234e3a8e308e976d2609f0b1a6e645a4d7a45074"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
