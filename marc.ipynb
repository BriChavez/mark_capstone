{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from numpy.random import choice\n",
    "import random\n",
    "import PyPDF2\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "\n",
    "\"\"\"create a dict of how what words follow which and how many times they did\"\"\"\n",
    "with open('data/Resume/test/test_resumes.txt', 'r') as resume_script:\n",
    "    # open txt file and read to string, string to lower\n",
    "    resume_file = resume_script.read()\n",
    "    resume_file = resume_file.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleared our test data of stop words\n",
    "words = word_tokenize(resume_file)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "filtered_text = [w for w in words if not w in stop_words]\n",
    "print(filtered_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # use regex to split text into words and punctuation\n",
    "# global resume_string\n",
    "resume_string = re.findall(r\"[\\w']+|[.,!?;]\", resume_file)\n",
    "\n",
    "# for loop that runs over every word in test\n",
    "resume_dict = {}\n",
    "\n",
    "for i, word in enumerate(resume_string[:-1]):\n",
    "    this_word = resume_string[i+1]\n",
    "    # if this_word is in dict, asssign it to 'next_count'\n",
    "    if this_word not in resume_dict:\n",
    "        next_count = {}\n",
    "        resume_dict[this_word] = next_count\n",
    "\n",
    "    # if not, create empty dictionary with this_word as the key and next_count as the value\n",
    "    else:\n",
    "        next_count = resume_dict[this_word]\n",
    "\n",
    "    if word in next_count:\n",
    "        next_count[word] += 1\n",
    "    else:\n",
    "        next_count[word] = 1\n",
    "this_word = resume_string[i+1]\n",
    "\n",
    "# print(resume_string)\n",
    "\n",
    "# name our new dictionary of words and count of next possible words to a new variable\n",
    "\n",
    "# print(resume_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"start the story\"\"\"\n",
    "\n",
    "# name variable with the first word in our list of words\n",
    "first_word = random.choice(seuss_string)\n",
    "print(first_word)\n",
    "# name the first word of our story as\n",
    "global story\n",
    "story = []\n",
    "\n",
    "\n",
    "def start_story(list):\n",
    "    \"\"\"function to start the story\"\"\"\n",
    "    if story == []:\n",
    "        # set story up with a first word\n",
    "        story.append(first_word)\n",
    "    else:\n",
    "        # dont start the story if its already been started\n",
    "        pass\n",
    "    return story\n",
    "\n",
    "\n",
    "start_story(seuss_string)\n",
    "# call function on our list of words from the text\n",
    "seuss_list = seuss_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def whos_next():\n",
    "    \"\"\"function to get the next word using weighted probability\"\"\"\n",
    "    current_word = story[-1]\n",
    "    for outer_word, inner_dict in seuss_dict.items():\n",
    "        # pick out our nested dict for specific word\n",
    "        word_self_total = inner_dict.items()\n",
    "        # get the next words and instances\n",
    "        total_occurances = inner_dict.values()\n",
    "        # seperate the instances\n",
    "        if outer_word == current_word:\n",
    "            # pull the dictionary for the current word\n",
    "            total = sum(total_occurances)\n",
    "            # add the total times a word followed current word\n",
    "            probs = []\n",
    "            # set empty variable for the percent chance of each word occuring\n",
    "            hopefuls = []\n",
    "            # set a list of all words that came after current word\n",
    "            likely = []\n",
    "            # set an empty list to grab the count of each word\n",
    "            for number in total_occurances:\n",
    "                # pull every number of times each word came after current\n",
    "                percent = number / total\n",
    "                # factor the percent chance of a word being next\n",
    "                probs.append(percent)\n",
    "                # add each percent to our probs list\n",
    "\n",
    "            for word, num in word_self_total:\n",
    "                # pull words and their values from our inner dict\n",
    "                hopefuls.append(word)\n",
    "                # add each word to our hopefuls list\n",
    "                likely.append(num)\n",
    "                # add each number to our likely list\n",
    "                global rng_says\n",
    "\n",
    "            rng_says = choice(hopefuls, p=probs)\n",
    "            # weighted rng based off the percent probability of word occuring\n",
    "            # return rng_says\n",
    "\n",
    "            next_word = str(rng_says)\n",
    "            # change rng output from numpy to string\n",
    "            story.append(next_word)\n",
    "            # add our next word string to the story\n",
    "            # current_word = story[-1]\n",
    "            # set current word to be the last word of the story\n",
    "\n",
    "\n",
    "whos_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"add words to the story\"\"\"\n",
    "\n",
    "\n",
    "while len(story) < 100:\n",
    "    whos_next()\n",
    "whole_story = ' '.join(story)\n",
    "print(whole_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "whole_story = re.sub(r'\\s([?.,!](?:\\s|$))', r'\\1', whole_story)\n",
    "\n",
    "\n",
    "print(whole_story)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_story = '.'.join(map((lambda x: x[0].upper()+x[1:])))\n",
    "\n",
    "# cap_sentences = [sentences.capitalize() for sentences in whole_story]\n",
    "sentences = re.split('[?.]', whole_story)\n",
    "\n",
    "\n",
    "def cap():\n",
    "    for string in whole_story:\n",
    "        return string[:1].capitalize() + string[1:].lower()\n",
    "\n",
    "\n",
    "print(sentences)\n",
    "# cap_sentences = [cap(sentences) for sentences in whole_story]\n",
    "\n",
    "# print(cap_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in story:\n",
    "    if i in puncuation:\n",
    "        x = story[i+1]\n",
    "        x.capatilize()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ef022e24af0d9896d2df829234e3a8e308e976d2609f0b1a6e645a4d7a45074"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
